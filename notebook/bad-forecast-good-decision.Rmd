---
title: "bad forecast good decision"
author: "Carl Boettiger"
output: github_document
---

```{r message=FALSE, warning=FALSE}
library(ggthemes)
library(hrbrthemes)
library(ggplot2)
library(Cairo)
library(extrafont)
extrafont::loadfonts()
ggplot2::theme_set(hrbrthemes::theme_ipsum_rc())
#theme_set(theme_solarized(base_size=16))

scale_colour_discrete <- function(...) scale_colour_solarized()
scale_fill_discrete <- function(...) scale_fill_solarized()
pal <- solarized_pal()(6)
txtcolor <- "#586e75"
```


```{r}
library(tidyverse)
library(MDPtoolbox)
library(expm)
library(mdplearning) # remotes::install_github("boettiger-lab/mdplearning")
```


```{r}
states <- seq(0,20, length.out = 200)
actions <- states
obs <- states
sigma_g <- 0.04
reward_fn <- function(x,h) pmin(x,h)
discount <- 0.99

# K is at twice max of f3; 8 * K_3 / 5
f1 <- function(x, h = 0, r = 2, K = 10 * 8 / 5){
  s <- pmax(x - h, 0)
  s + s * (r * (1 - s / K) )
}
f2 <- function(x, h = 0, r = 1, K = 10){
  s <- pmax(x - h, 0)
  s + s * (r * (1 - s / K) )
}

# max is at 4 * K / 5 
f3  <- function(x, h = 0, r = .002, K = 10){
  s <- pmax(x - h, 0)
  s + s ^ 4 * r * (1 - s / K)
}

f4  <- function(x, h = 0, r = 4e-7, K = 10){
  s <- pmax(x - h, 0)
  s + s ^ 8 * r * (1 - s / K) + s * (1 - s / K)
}

models <- list(f1 = f1, f2 = f2, f3 = f3)

true_model <- "f3"

## Could consider ricker-style versions of these models. need to take care to set limits correctly
## to get correspondence (recall x * e^y ~ x *(1 + y) for small y), e.g. something like
#f1 <- function(x, h = 0, r = .1, K = 15){
#  s <- pmax(x - h, 0)
#  s * exp(r * (1 - s / K) )
#}
#f3  <- function(x, h = 0, r = .01, K = 10){
#  s <- pmax(x - h, 0)
#  s * exp(s ^ 3 * r * (1 - s / K))
#}

```


```{r}
d <- map_dfc(models, function(f) f(states) - states) %>% mutate(state = states)
d %>% pivot_longer(names(models), "model") %>%
  ggplot(aes(state, value, col=model)) +
  geom_point() + 
  geom_hline(aes(yintercept = 0)) + 
  coord_cartesian(ylim = c(-5, 8), xlim = c(0,16))
```




```{r}
# A function to compute the transition matrices for each model:
transition_matrices <- function(f,
                      states,
                      actions,
                      sigma_g){

  n_s <- length(states)
  n_a <- length(actions)

  transition <- array(0, dim = c(n_s, n_s, n_a))
  for (k in 1:n_s) {
    for (i in 1:n_a) {
      nextpop <- f(states[k], actions[i])
      if(nextpop <= 0){
        transition[k, , i] <- c(1, rep(0, n_s - 1))
      } else if(sigma_g > 0){
        x <- dlnorm(states, log(nextpop), sdlog = sigma_g)
        if(sum(x) == 0){ ## nextpop is computationally zero
          transition[k, , i] <- c(1, rep(0, n_s - 1))
        } else {
          x <- x / sum(x) # normalize evenly. 
          ## pile excess on boundary
          #N <- plnorm(states[n_s], log(nextpop), sigma_g)
          #x <- x * N / sum(x)
          #x[n_s] <- 1 - N + x[n_s]
          transition[k, , i] <- x
        }
      } else {
        stop("sigma_g not > 0")
      }
      reward[k, i] <- reward_fn(states[k], actions[i])
    }
  }
  transition
}

## Reward matrix is shared by each model
n_s <- length(states)
n_a <- length(actions)
reward <- array(0, dim = c(n_s, n_a))
for (k in 1:n_s) {
  for (i in 1:n_a) {
    reward[k, i] <- reward_fn(states[k], actions[i])
  }
}

transitions <- lapply(models, function(f) transition_matrices(f, states, actions, sigma_g))

```

## Forecasting performance

```{r}

sim <- function(f, x0, Tmax, reps = 1){
  map_dfr(1:reps, 
          function(i){
            x <- numeric(length(Tmax))
            x[1] <- x0
            for(t in 2:Tmax){
              mu <- f(x[t-1])
              x[t] <-  rlnorm(1, log(mu), sdlog = sigma_g)
            }
            tibble(t = 1:Tmax, x= x)
          },
          .id="rep")
}
models[names(models) != true_model]

true_sim <- sim(models[[true_model]], 5, 100, 1) %>%
  mutate(model = true_model, mean = x, ymin = NA, ymax = NA)
df <- map_dfr(models[1:2], sim, 5, 100, 100, .id = "model")
forecast <- df %>% 
  group_by(model, t) %>% summarise(mean = mean(x), sd = sd(x))

forecast %>%
  ggplot(aes(t, mean, col=model)) +
  geom_line() + 
  geom_line(data = true_sim) + 
  geom_ribbon(aes(fill= model, ymin = mean - 2*sd, ymax = mean + 2*sd), alpha=0.1, col=NA)


```

```{r}
d <- forecast %>% group_by(model) %>% 
  mutate(true = true_sim$x) %>%
  summarise(rmsd = sqrt(mean( (mean - true) ^ 2 )),
            r2 = 1 - sum( (mean - true) ^ 2  ) / sum( mean ^ 2 )
            )
rmsd <- d %>% pull(rmsd)
names(rmsd) <- d %>% pull(model)

opt <- sqrt(mean((true_sim$x - 10)^2))
opt
```

Model 2 clearly outperforms model 1 in predictive capacity. The root mean squared deviation between the model 2 mean and the realization is `r rmsd[["f2"]]`, far lower than model 1 at `r rmsd[["f1"]]`.



```{r}
# Simulate the evolution of probability distribution directly using a matrix exponent
prob_dynamics <- function(M, X, Tmax){
  probability <- t(M) %^% Tmax %*% X 
  data.frame(state = states, probability)
}

x0 <- which.min(abs(states - 6))
X <- numeric(length=length(states))
X[x0] <- 1

map_dfr(transitions, 
        function(m) prob_dynamics(m[,,1], X, 100),
        .id = "model") %>%
  group_by(model) %>%
  ggplot(aes(state, probability, col=model)) +
  geom_line()
```




## Model analysis



```{r}

policies <- map_dfr(transitions, function(P){
  soln <- mdp_value_iteration(P, reward, discount = discount)
  tibble(states, policy = soln$policy, escapement = states - actions[soln$policy])
}, .id = "model")

```


```{r}
policies %>%
  ggplot(aes(states,escapement, col=model, lty=model)) + geom_line(lwd=2)
```






Management under the wrong model (`f3`)



```{r}
library(mdplearning)
Tmax <- 100
x0 <- which.min(abs(states - 6))
reps <- 5
set.seed(12345)


## Simulate each policy reps times, with `f3` as the true model:

sims <- map_dfr(names(transitions), 
                function(m){
                  policy <- policies %>% filter(model == m) %>% pull(policy)
                  map_dfr(1:reps, 
                          function(i){
                            mdp_planning(transitions[[true_model]], reward, discount,
                                     policy = policy, x0 = x0, Tmax = Tmax) %>%
                              select(value, state_index = state, time, action_index = action)  %>% 
                              mutate(state = states[state_index]) # index->value
                            },
                          .id = "reps")
                },
                .id = "model")


```

```{r}
fig_ts <- 
  sims %>%
  filter(time < 25) %>%
  ggplot(aes(time, state, col=model, group = interaction(model,reps))) + 
  geom_line(alpha=0.5) 
fig_ts
```

Note that the pattern is not driven merely be differences in the unfished equilibrium.  Compare forecast performance under management:

```{r}
scores <- sims %>%
  mutate(next_state = dplyr::lead(state_index), model = as.integer(model)) %>%
  select(time, state_index, next_state, action_index, model, reps) %>% 
  rowwise() %>%
  mutate(prob =  transitions[[model]][state_index, next_state, action_index] )

scores %>% 
  group_by(reps, model) %>%
  summarise(score = sum(log(prob))) %>%
  group_by(model) %>% summarise(mean_score = mean(score))

```





```{r fig.cap = "Corresponding utility (measured as mean net present value, that is: cumulative value, discounting future values by $\\delta^t$, averaged across replicates). Note that the exepcted utility under model 1, which has the worst forecast, is nearly identical to the optimal utility achieved by managing under the correct model, 3.  The utility derived from model 2 is far smaller, despite it's overall better performance in long term forecasts."}
##  Net Present Value accumulates over time, equivalent for models with near-identical management stategy
npv_df <- sims %>% 
  group_by(model, reps) %>%
  mutate(npv = cumsum(value * discount ^ time)) %>%
  group_by(time, model)  %>% 
  summarise(mean_npv = mean(npv))
npv_df %>%
  ggplot(aes(time, mean_npv, fill=model)) +
  ## Area plots are weird but avoids overplotting
  geom_area(alpha = 0.9) +
   #geom_ribbon(aes(ymin = 0, ymax = mean_npv), alpha = 0.6) + 
  ylab("Net present value") + xlab("time")  

```

## Conclusions



- A good forecast does not mean good management
- A bad forecast does not mean the model is bad for management
- A model permitting successful management does not imply the model is "correct" or generally "good at forecasting"


Model with the egregiously optimistic long-term forecast for the stock size of an unexploited fishery nevertheless actually leads to more conservative management.  In contrast, the model which correctly predicts the long-term average stock size without fishing nevertheless leads to substantial overharvesting.  




```{r}
```

